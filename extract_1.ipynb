{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1dEvEku0r9OeWgBx_OSBl0Duxlcd6H71d",
      "authorship_tag": "ABX9TyOmxOu5QFLYNf30jx3dq1el",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maverick98/TopoGAT/blob/master/extract_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjhFWtV6ZCqX"
      },
      "outputs": [],
      "source": [
        "import nbformat\n",
        "\n",
        "def extract_log_block(notebook_path, dataset, variant):\n",
        "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "        nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "    start_phrase = f\"Running experiment on {dataset} with variant '{variant}'\"\n",
        "    end_phrase = \"All analysis completed and saved.\"\n",
        "\n",
        "    collecting = False\n",
        "    log_lines = []\n",
        "\n",
        "    for cell in nb.cells:\n",
        "        sources = []\n",
        "\n",
        "        if cell.cell_type == 'markdown':\n",
        "            sources = cell.source.splitlines()\n",
        "        elif cell.cell_type == 'code':\n",
        "            sources = cell.source.splitlines()\n",
        "\n",
        "            # Also check outputs (like printed logs)\n",
        "            for output in cell.get(\"outputs\", []):\n",
        "                if output.output_type == \"stream\":\n",
        "                    sources += output.text.splitlines()\n",
        "                elif output.output_type == \"execute_result\":\n",
        "                    if isinstance(output.data, dict):\n",
        "                        sources += output.data.get('text/plain', '').splitlines()\n",
        "\n",
        "        for line in sources:\n",
        "            if start_phrase in line:\n",
        "                collecting = True\n",
        "                log_lines.append(line)\n",
        "                continue\n",
        "\n",
        "            if collecting:\n",
        "                log_lines.append(line)\n",
        "                if end_phrase in line:\n",
        "                    collecting = False\n",
        "\n",
        "    if log_lines:\n",
        "        print(f\"\\n📋 Log Block for {dataset.upper()} - {variant}:\\n\")\n",
        "        print(\"\\n\".join(log_lines))\n",
        "    else:\n",
        "        print(f\"\\n❌ Could not extract log block for {dataset} with variant '{variant}'.\")\n",
        "\n",
        "# Example usage:\n",
        "extract_log_block(\"TopoGAT_vs_GAT.ipynb\", dataset=\"MUTAG\", variant=\"basic\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nbformat\n",
        "\n",
        "def extract_summary_block(full_block: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract the section from 'Saved summary to' to 'All analysis completed and saved.' within a full experiment block.\n",
        "    \"\"\"\n",
        "    lines = full_block.splitlines()\n",
        "    start_index = None\n",
        "    end_index = None\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        if start_index is None and 'Saved summary to' in line:\n",
        "            start_index = i\n",
        "        if 'All analysis completed and saved' in line:\n",
        "            end_index = i\n",
        "            break\n",
        "\n",
        "    if start_index is not None and end_index is not None and start_index <= end_index:\n",
        "        return '\\n'.join(lines[start_index:end_index + 1])\n",
        "    else:\n",
        "        return '❌ Summary section not found.'\n",
        "\n",
        "def extract_log_block(notebook_path, dataset, variant):\n",
        "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "        nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "    start_phrase = f\"Running experiment on {dataset} with variant '{variant}'\"\n",
        "    end_phrase = \"All analysis completed and saved.\"\n",
        "\n",
        "    collecting = False\n",
        "    log_lines = []\n",
        "\n",
        "    for cell in nb.cells:\n",
        "        sources = []\n",
        "\n",
        "        if cell.cell_type in ('markdown', 'code'):\n",
        "            sources = cell.source.splitlines()\n",
        "\n",
        "            # Also check outputs for code cells\n",
        "            if cell.cell_type == 'code':\n",
        "                for output in cell.get(\"outputs\", []):\n",
        "                    if output.output_type == \"stream\":\n",
        "                        sources += output.text.splitlines()\n",
        "                    elif output.output_type == \"execute_result\":\n",
        "                        if isinstance(output.data, dict):\n",
        "                            sources += output.data.get('text/plain', '').splitlines()\n",
        "\n",
        "        for line in sources:\n",
        "            if start_phrase in line:\n",
        "                collecting = True\n",
        "                log_lines.append(line)\n",
        "                continue\n",
        "\n",
        "            if collecting:\n",
        "                log_lines.append(line)\n",
        "                if end_phrase in line:\n",
        "                    collecting = False\n",
        "\n",
        "    if log_lines:\n",
        "        full_block = \"\\n\".join(log_lines)\n",
        "        summary = extract_summary_block(full_block)\n",
        "        print(f\"\\n📋 Summary for {dataset.upper()} - {variant}:\\n\")\n",
        "        print(summary)\n",
        "    else:\n",
        "        print(f\"\\n❌ Could not extract log block for {dataset} with variant '{variant}'.\")\n",
        "\n",
        "# Example usage:\n",
        "extract_log_block(\"TopoGAT_vs_GAT.ipynb\", dataset=\"PROTEINS\", variant=\"attn\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "L70wDjJfc1Zl",
        "outputId": "7e8effac-c263-4331-9f25-a55484a0a4ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📋 Summary for PROTEINS - attn:\n",
            "\n",
            " Saved summary to /content/drive/MyDrive/topogat/PROTEINS/attn/summary_topogat.csv\n",
            " Saved summary to /content/drive/MyDrive/topogat/PROTEINS/attn/summary_gat.csv\n",
            " Exported LaTeX table to /content/drive/MyDrive/topogat/PROTEINS/attn/topogat_table.tex\n",
            " Exported LaTeX table to /content/drive/MyDrive/topogat/PROTEINS/attn/gat_table.tex\n",
            " Exported comparison summary to /content/drive/MyDrive/topogat/PROTEINS/attn/comparison_summary.csv\n",
            " Representative Seed: 0 (Closest accuracy to mean 0.7101)\n",
            " Representative Metrics: {'accuracy': 0.7085201793721974, 'precision': 0.6971766848816029, 'recall': 0.6653793922933288, 'f1': 0.6702159124519373, 'roc_auc': np.float64(0.6829910032252589), 'log_loss': 0.6294615844584237}\n",
            " Representative Seed: 14 (Closest accuracy to mean 0.6435)\n",
            " Representative Metrics: {'accuracy': 0.6457399103139013, 'precision': 0.6318011257035647, 'recall': 0.5827861952861954, 'f1': 0.5691927713789646, 'roc_auc': np.float64(0.4738215488215488), 'log_loss': 0.6741731995870969}\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.85      0.78       137\n",
            "           1       0.67      0.48      0.56        86\n",
            "\n",
            "    accuracy                           0.71       223\n",
            "   macro avg       0.70      0.67      0.67       223\n",
            "weighted avg       0.70      0.71      0.70       223\n",
            "\n",
            " Saved confusion matrix to /content/drive/MyDrive/topogat/PROTEINS/attn/seed_0/confusion_topogat_rep_0.png\n",
            " Saved PR curve to /content/drive/MyDrive/topogat/PROTEINS/attn/seed_0/pr_curve_topogat_rep_0.png\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.85      0.74       143\n",
            "           1       0.42      0.20      0.27        80\n",
            "\n",
            "    accuracy                           0.61       223\n",
            "   macro avg       0.54      0.52      0.50       223\n",
            "weighted avg       0.57      0.61      0.57       223\n",
            "\n",
            " Saved confusion matrix to /content/drive/MyDrive/topogat/PROTEINS/attn/seed_14/confusion_gat_rep_14.png\n",
            " Saved PR curve to /content/drive/MyDrive/topogat/PROTEINS/attn/seed_14/pr_curve_gat_rep_14.png\n",
            "Saved statistical comparison to /content/drive/MyDrive/topogat/PROTEINS/attn/paired_ttest_results.txt\n",
            "Saved boxplot to /content/drive/MyDrive/topogat/PROTEINS/attn/metric_comparison_boxplot.png\n",
            "\n",
            "All analysis completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nbformat\n",
        "import os\n",
        "\n",
        "def extract_summary_block(notebook_path, dataset, variant, save_dir):\n",
        "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "        nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "    experiment_header = f\"Running experiment on {dataset} with variant '{variant}'\"\n",
        "    start_phrase = \"Saved summary to\"\n",
        "    end_phrase = \"All analysis completed and saved.\"\n",
        "\n",
        "    in_experiment = False\n",
        "    collecting = False\n",
        "    summary_lines = []\n",
        "\n",
        "    for cell in nb.cells:\n",
        "        lines = []\n",
        "\n",
        "        if cell.cell_type == 'markdown' or cell.cell_type == 'code':\n",
        "            lines.extend(cell.source.splitlines())\n",
        "\n",
        "            for output in cell.get(\"outputs\", []):\n",
        "                if output.output_type == \"stream\":\n",
        "                    lines += output.text.splitlines()\n",
        "                elif output.output_type == \"execute_result\" and isinstance(output.data, dict):\n",
        "                    lines += output.data.get('text/plain', '').splitlines()\n",
        "\n",
        "        for line in lines:\n",
        "            if experiment_header in line:\n",
        "                in_experiment = True\n",
        "\n",
        "            if in_experiment:\n",
        "                if start_phrase in line:\n",
        "                    collecting = True\n",
        "                if collecting:\n",
        "                    summary_lines.append(line)\n",
        "                    if end_phrase in line:\n",
        "                        in_experiment = False\n",
        "                        collecting = False\n",
        "\n",
        "    if summary_lines:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        save_path = os.path.join(save_dir, f\"analysis_{dataset}_{variant}.log\")\n",
        "\n",
        "        with open(save_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"\\n\".join(summary_lines))\n",
        "\n",
        "        print(f\"✅ Extracted summary saved to:\\n{save_path}\")\n",
        "    else:\n",
        "        print(f\"❌ Could not find summary block for {dataset} with variant '{variant}'.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PvXzeUUfyW2",
        "outputId": "b12faef4-4455-41a6-f17a-665097d0111e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extracted summary saved to:\n",
            "/content/drive/MyDrive/topogat_vs_gat/MUTAG/analysis_MUTAG_basic.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "extract_summary_block(\n",
        "    notebook_path=\"TopoGAT_vs_GAT.ipynb\",\n",
        "    dataset=\"MUTAG\",\n",
        "    variant=\"basic\",\n",
        "    save_dir=\"/content/drive/MyDrive/topogat_vs_gat/MUTAG\"\n",
        ")"
      ],
      "metadata": {
        "id": "9Yax0EJigVlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nbformat\n",
        "\n",
        "def extract_summary_block(notebook_path, dataset, variant, base_dataset_dir):\n",
        "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "        nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "    start_phrase = f\"Running experiment on {dataset} with variant '{variant}'\"\n",
        "    collect_from = \"Saved summary to\"\n",
        "    end_phrase = \"All analysis completed and saved.\"\n",
        "\n",
        "    collecting = False\n",
        "    found_section = False\n",
        "    log_lines = []\n",
        "\n",
        "    for cell in nb.cells:\n",
        "        sources = []\n",
        "\n",
        "        if cell.cell_type == 'markdown':\n",
        "            sources = cell.source.splitlines()\n",
        "        elif cell.cell_type == 'code':\n",
        "            sources = cell.source.splitlines()\n",
        "            for output in cell.get(\"outputs\", []):\n",
        "                if output.output_type == \"stream\":\n",
        "                    sources += output.text.splitlines()\n",
        "                elif output.output_type == \"execute_result\":\n",
        "                    if isinstance(output.data, dict):\n",
        "                        sources += output.data.get('text/plain', '').splitlines()\n",
        "\n",
        "        for line in sources:\n",
        "            if start_phrase in line:\n",
        "                found_section = True\n",
        "\n",
        "            if found_section and collect_from in line:\n",
        "                collecting = True\n",
        "\n",
        "            if collecting:\n",
        "                log_lines.append(line)\n",
        "                if end_phrase in line:\n",
        "                    collecting = False\n",
        "                    found_section = False\n",
        "\n",
        "    if log_lines:\n",
        "        os.makedirs(base_dataset_dir, exist_ok=True)\n",
        "        filename = f\"analysis_{dataset}_{variant}.log\"\n",
        "        save_path = os.path.join(base_dataset_dir, filename)\n",
        "        with open(save_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"\\n\".join(log_lines))\n",
        "        print(f\"✅ Saved: {save_path}\")\n",
        "    else:\n",
        "        print(f\"❌ No summary block found for {dataset} with variant '{variant}'.\")\n",
        "\n",
        "def extract_all_variants(notebook_path, dataset, base_dir):\n",
        "    variants = [\"basic\", \"node_aware\", \"gated\", \"attn\"]\n",
        "    dataset_dir = os.path.join(base_dir, dataset)\n",
        "    for variant in variants:\n",
        "        extract_summary_block(notebook_path, dataset, variant, dataset_dir)\n",
        "\n",
        "# Example usage:\n",
        "notebook_path = \"TopoGAT_vs_GAT.ipynb\"\n",
        "base_dir = \"/content/drive/MyDrive/topogat_vs_gat\"\n",
        "datasets = [\"MUTAG\", \"PTC_MR\", \"PROTEINS\", \"ENZYMES\"]\n",
        "\n",
        "for dataset in datasets:\n",
        "    extract_all_variants(notebook_path, dataset, base_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp1-bl08gruX",
        "outputId": "34b5bd98-85a6-4c83-d984-9d94cfdc8b06"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/MUTAG/analysis_MUTAG_basic.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/MUTAG/analysis_MUTAG_node_aware.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/MUTAG/analysis_MUTAG_gated.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/MUTAG/analysis_MUTAG_attn.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/PTC_MR/analysis_PTC_MR_basic.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/PTC_MR/analysis_PTC_MR_node_aware.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/PTC_MR/analysis_PTC_MR_gated.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/PTC_MR/analysis_PTC_MR_attn.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/PROTEINS/analysis_PROTEINS_basic.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/PROTEINS/analysis_PROTEINS_node_aware.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/PROTEINS/analysis_PROTEINS_gated.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/PROTEINS/analysis_PROTEINS_attn.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/ENZYMES/analysis_ENZYMES_basic.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/ENZYMES/analysis_ENZYMES_node_aware.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/ENZYMES/analysis_ENZYMES_gated.log\n",
            "✅ Saved: /content/drive/MyDrive/topogat_vs_gat/ENZYMES/analysis_ENZYMES_attn.log\n"
          ]
        }
      ]
    }
  ]
}